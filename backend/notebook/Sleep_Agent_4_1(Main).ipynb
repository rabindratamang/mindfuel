{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7FZKUcOMsXR",
        "outputId": "82df0c43-a805-487a-d967-d5fd8d9bdfd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m364.6/364.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-openai langchain langgraph langchain_community langgraph-supervisor langchain-chroma langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VMJAVuNM0-D"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph_supervisor import create_supervisor\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import (\n",
        "    HumanMessage,\n",
        ")\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "import requests\n",
        "key = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyH_8oHkMsUK"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(api_key=key,model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD0Mq47RRhbU"
      },
      "source": [
        "# Langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRpjueobdzjz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=\"key\"\n",
        "#\"key\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"Sleep 4o\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLjKdgZddzhB"
      },
      "outputs": [],
      "source": [
        "# key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lULLtUoQwd_U",
        "outputId": "4b3233e5-15aa-4143-a648-44f510652d20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Tracing enabled: true\n"
          ]
        }
      ],
      "source": [
        "print(\"‚úÖ Tracing enabled:\", os.environ.get(\"LANGCHAIN_TRACING_V2\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az-xnTIBUt-k"
      },
      "source": [
        "# Spotify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGyN54itUtvj"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from typing import List\n",
        "import requests\n",
        "\n",
        "# Optional: Use a dataclass to format results more clearly\n",
        "def get_spotify_token(client_id: str, client_secret: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetches a bearer token from Spotify using client credentials.\n",
        "    \"\"\"\n",
        "    url = 'https://accounts.spotify.com/api/token'\n",
        "    headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
        "    data = {'grant_type': 'client_credentials'}\n",
        "    response = requests.post(url, headers=headers, data=data, auth=(client_id, client_secret))\n",
        "    response.raise_for_status()\n",
        "    return response.json()['access_token']\n",
        "\n",
        "import requests\n",
        "\n",
        "@tool\n",
        "def search_spotify_playlists(query: str) -> dict:\n",
        "    \"\"\"\n",
        "    Search for Spotify playlists using a keyword (e.g., \"sleep\", \"meditation\").\n",
        "\n",
        "    Returns a JSON object with the top 5 playlists including name, description, image, link, owner, and track count.\n",
        "    \"\"\"\n",
        "    client_id = \"key\"\n",
        "    client_secret = \"key\"\n",
        "\n",
        "    try:\n",
        "        token = get_spotify_token(client_id, client_secret)\n",
        "\n",
        "        headers = {\n",
        "            'Authorization': f'Bearer {token}'\n",
        "        }\n",
        "        params = {\n",
        "            'q': query,\n",
        "            'type': 'playlist',\n",
        "            'limit': 5\n",
        "        }\n",
        "        url = 'https://api.spotify.com/v1/search'\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        playlists = response.json().get('playlists', {}).get('items', [])\n",
        "\n",
        "        if not playlists:\n",
        "            return {\"message\": \"No playlists found for your query.\"}\n",
        "\n",
        "        result = {\n",
        "            \"query\": query,\n",
        "            \"total\": len(playlists),\n",
        "            \"playlists\": []\n",
        "        }\n",
        "\n",
        "        for pl in playlists:\n",
        "            if pl is None:\n",
        "                continue\n",
        "\n",
        "            result[\"playlists\"].append({\n",
        "                \"name\": pl.get('name'),\n",
        "                \"description\": pl.get('description'),\n",
        "                \"external_url\": pl.get('external_urls', {}).get('spotify'),\n",
        "                \"image\": pl.get('images', [{}])[0].get('url'),\n",
        "                \"owner\": {\n",
        "                    \"name\": pl.get('owner', {}).get('display_name'),\n",
        "                    \"url\": pl.get('owner', {}).get('external_urls', {}).get('spotify')\n",
        "                },\n",
        "                \"tracks\": {\n",
        "                    \"url\": pl.get('tracks', {}).get('href'),\n",
        "                    \"total\": pl.get('tracks', {}).get('total')\n",
        "                }\n",
        "            })\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9qB18rHUtr0"
      },
      "outputs": [],
      "source": [
        "spotify_assistant = create_react_agent(\n",
        "    model=model,\n",
        "    tools=[search_spotify_playlists],\n",
        "    prompt=(\n",
        "        \"You are a helpful Spotify assistant. Your job is to help users discover Spotify playlists \"\n",
        "        \"based on their search queries using the tool provided.\\n\\n\"\n",
        "        \"üß† Think step-by-step, and always call the `search_spotify_playlists` tool with the user query.\\n\"\n",
        "        \"üì¶ When returning results to the user, format the final output in **JSON** using this structure:\\n\\n\"\n",
        "        \"{\\n\"\n",
        "        '  \"query\": string,\\n'\n",
        "        '  \"total\": integer,\\n'\n",
        "        '  \"playlists\": [\\n'\n",
        "        \"    {\\n\"\n",
        "        '      \"name\": string,\\n'\n",
        "        '      \"description\": string,\\n'\n",
        "        '      \"external_url\": string,\\n'\n",
        "        '      \"image\": string,\\n'\n",
        "        '      \"owner\": {\"name\": string, \"url\": string},\\n'\n",
        "        '      \"tracks\": {\"url\": string, \"total\": integer}\\n'\n",
        "        \"    },\\n\"\n",
        "        \"    ...\\n\"\n",
        "        \"  ]\\n\"\n",
        "        \"}\\n\\n\"\n",
        "        \"Only return JSON. Do not add any extra commentary or text outside of the JSON structure.\"\n",
        "    ),\n",
        "    name=\"spotify_assistant\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqBv0gGdV0pd"
      },
      "source": [
        "# Sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGAyjzlfMZRz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "class SleepCoachAgent:\n",
        "    def __init__(self, api_key):\n",
        "        self.llm = ChatOpenAI(openai_api_key=api_key, model=\"gpt-4o-mini\", max_tokens=4096)\n",
        "        self.prompt = PromptTemplate(\n",
        "    template = \"\"\"\n",
        "You are a smart, caring, and proactive Sleep Coach AI. Your role is to help users reflect on their sleep, understand behavioral patterns, and build sustainable habits for better rest and recovery.\n",
        "\n",
        "Your job is to analyze the user's sleep-related input and provide a rich JSON response structured across multiple categories.\n",
        "\n",
        "==============================\n",
        "CONTEXT:\n",
        "{context}\n",
        "\n",
        "USER INPUT:\n",
        "\"{input}\"\n",
        "==============================\n",
        "\n",
        "üîç ANALYSIS GOALS:\n",
        "1. Identify the user's sleep issue, need, or question\n",
        "2. Extract important data (e.g., time, feelings, habits, metrics)\n",
        "3. Provide a brief but insightful summary of the user's sleep pattern\n",
        "4. Detect mood and emotional cues if present\n",
        "5. Generate a personalized wind-down routine\n",
        "6. Recommend optimal sleep and wake-up timing\n",
        "7. Suggest behavior/environment improvements\n",
        "8. Perform a basic sleep disorder screening\n",
        "9. Propose follow-up actions and metrics to track\n",
        "10. Tag context categories (e.g., stress, diet, tech use)\n",
        "\n",
        "üì¶ RESPONSE FORMAT (STRICTLY VALID JSON):\n",
        "Double quotes must be used.\n",
        "Avoid any markdown formatting or extra text.\n",
        "Response must end cleanly with the final `}}`.\n",
        "\n",
        "RESPONSE FORMAT:\n",
        "{{\n",
        "  \"sleepAssessment\": {{\n",
        "    \"issue\": \"string\",  // e.g. 'difficulty falling asleep'\n",
        "    \"confidence\": number,  // 0.0 to 1.0\n",
        "    \"severity\": \"low\" | \"medium\" | \"high\",\n",
        "    \"summary\": \"string\",\n",
        "    \"sleepHistoryDetected\": boolean,\n",
        "    \"userMood\": \"tired\" | \"refreshed\" | \"anxious\" | \"groggy\" | \"unknown\",\n",
        "    \"sleepDurationTrend\": \"increasing\" | \"decreasing\" | \"stable\" | \"unknown\"\n",
        "  }},\n",
        "  \"routineRecommendation\": {{\n",
        "    \"windDown\": [\"string\"],  // calming activities\n",
        "    \"avoidBeforeBed\": [\"string\"],  // caffeine, screens, etc.\n",
        "    \"optimalSleepTime\": \"string\",  // e.g. \"10:45 PM\"\n",
        "    \"optimalWakeTime\": \"string\",  // e.g. \"6:30 AM\"\n",
        "    \"reminders\": [\"string\"]\n",
        "  }},\n",
        "  \"tips\": {{\n",
        "    \"immediateActions\": [\"string\"],  // changes starting tonight\n",
        "    \"lifestyleChanges\": [\"string\"],  // longer-term habits\n",
        "    \"environmentSuggestions\": [\"string\"]  // bedroom, lighting, etc.\n",
        "  }},\n",
        "  \"recommendations\": {{\n",
        "      \"immediate\": [\"string\"], // 3-4 immediate actionable suggestions\n",
        "      \"content\": {{\n",
        "      \"spotify\": {{\n",
        "          \"genres\": [\"string\"], // ambient, classical, nature sounds, etc.\n",
        "          \"energy\": number, // 0-1 (0=calm, 1=energetic)\n",
        "          \"valence\": number, // 0-1 (0=sad, 1=happy)\n",
        "          \"mood\": \"string\" // relaxing, uplifting, focus, etc.\n",
        "      }},\n",
        "      }}\n",
        "  }},\n",
        "  \"disorderCheck\": {{\n",
        "    \"riskLevel\": \"low\" | \"medium\" | \"high\",\n",
        "    \"symptoms\": [\"string\"],\n",
        "    \"recommendations\": [\"string\"],\n",
        "    \"complianceRisk\": \"low\" | \"medium\" | \"high\"  // likelihood user may not follow\n",
        "  }},\n",
        "  \"followUp\": {{\n",
        "    \"checkInPeriod\": \"daily\" | \"weekly\" | \"custom\",\n",
        "    \"trackMetrics\": [\"string\"],  // e.g. \"hours slept\", \"interruptions\"\n",
        "    \"goals\": [\"string\"]  // e.g. \"reduce latency to < 20 minutes\"\n",
        "  }},\n",
        "  \"metadata\": {{\n",
        "    \"wordCount\": number,\n",
        "    \"timeOfDayMentioned\": \"morning\" | \"afternoon\" | \"evening\" | \"night\" | \"unknown\",\n",
        "    \"contextTags\": [\"string\"]  // e.g. [\"stress\", \"caffeine\", \"screen use\"]\n",
        "  }}\n",
        "}}\n",
        "            GUIDELINES:\n",
        "            - Be empathetic and non-judgmental\n",
        "            - Focus on actionable insights\n",
        "            - Consider cultural sensitivity\n",
        "            - If serious mental health concerns are detected, prioritize professional help recommendations\n",
        "            - Tailor content suggestions to the specific mood and needs identified\n",
        "            - Use clear, supportive language\n",
        "            - Avoid medical diagnosis or treatment advice\n",
        "            - Encourage professional help when appropriate\n",
        "\n",
        "           [SYSTEM RULES]\n",
        "            1. Respond **ONLY** with valid JSON that starts with `{{` and ends with `}}`.\n",
        "            2. **Never** include:\n",
        "            - Text before `{{` or after `}}`\n",
        "            - Markdown/code blocks (```json```)\n",
        "            - Explanatory comments\n",
        "            3. If you violate this, the API will reject your response.\n",
        "\n",
        "            [EXAMPLE OF CORRECT RESPONSE]\n",
        "            {{\n",
        "                \"sleepAssessment\": {{\n",
        "                    \"issue\": \"Difficulty falling asleep\",\n",
        "                    \"confidence\": 0.8\n",
        "                }}\n",
        "            }}\n",
        "\n",
        "            [EXAMPLE OF INCORRECT RESPONSE]\n",
        "            USER INPUT: \"{input}\"\\n\n",
        "            {{\n",
        "                \"sleepAssessment\": {{\n",
        "                    \"issue\": \"Difficulty falling asleep\"\n",
        "                }}\n",
        "            }}\n",
        "\n",
        "            Return only the JSON object with no additional text or formatting.\n",
        "\"\"\"\n",
        ",\n",
        "    input_variables=[\"context\", \"input\"]\n",
        ")\n",
        "        from langchain.chains import LLMChain\n",
        "        self.chain = LLMChain(prompt=self.prompt, llm=self.llm, verbose=False)\n",
        "\n",
        "        # self.chain = self.prompt | self.llm\n",
        "        self.collection = self._get_collection()\n",
        "\n",
        "    def _get_collection(self):\n",
        "        # You can customize this to use a DB or tracking log if needed\n",
        "        return []\n",
        "\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    import json\n",
        "\n",
        "    def get_spotify_recommendation(self, spotify_recommendation: dict):\n",
        "        try:\n",
        "            # Step 1: Build structured prompt\n",
        "            genres = spotify_recommendation.get(\"genres\", [])\n",
        "            mood = spotify_recommendation.get(\"mood\", \"\")\n",
        "            energy = spotify_recommendation.get(\"energy\", \"\")\n",
        "            valence = spotify_recommendation.get(\"valence\", \"\")\n",
        "\n",
        "            prompt = (\n",
        "                \"Find a Spotify playlist or track recommendation with the following:\\n\"\n",
        "                f\"- Genres: {', '.join(genres)}\\n\"\n",
        "                f\"- Mood: {mood}\\n\"\n",
        "                f\"- Energy level: {energy} (0=low, 1=high)\\n\"\n",
        "                f\"- Valence (positivity): {valence} (0=sad, 1=happy)\\n\\n\"\n",
        "                \"Only return JSON with: title, spotify_url, duration_seconds, thumbnail, and artist/playlist details.\"\n",
        "            )\n",
        "            # print(\"üéµ Prompt to Spotify agent:\\n\", prompt)\n",
        "\n",
        "            # Step 2: Call the Spotify agent\n",
        "            response = spotify_assistant.invoke({\n",
        "                \"messages\": [HumanMessage(content=prompt)]\n",
        "            })\n",
        "\n",
        "            # Step 3: Extract the last message's content\n",
        "            content = response[\"messages\"][-1].content\n",
        "            # print(\"üì¶ Raw content from Spotify assistant:\\n\", content)\n",
        "\n",
        "            # Step 4: Parse the JSON content\n",
        "            if isinstance(content, dict):\n",
        "                return content  # already a dict\n",
        "\n",
        "            if isinstance(content, str):\n",
        "                try:\n",
        "                    return json.loads(content)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    return {\"error\": f\"Failed to parse JSON: {str(e)}\"}\n",
        "\n",
        "            return {\"error\": \"Unknown content format from Spotify assistant.\"}\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Exception occurred: {str(e)}\"}\n",
        "\n",
        "    def run(self, user_input, user_id=None, context=None):\n",
        "        try:\n",
        "            context_str = \"\"\"\n",
        "                - MindFuel is a mental wellness app that helps users track mood, get personalized content recommendations, and improve mental health\n",
        "                - Users share their thoughts, feelings, and current state\n",
        "                - Your analysis will be used to provide personalized YouTube videos, articles, Spotify playlists, and meditation recommendations\n",
        "                - Be empathetic, supportive, and professional in your analysis\n",
        "            \"\"\"\n",
        "            prompt_vars = {\n",
        "                \"context\": context_str,\n",
        "                \"input\": user_input,\n",
        "            }\n",
        "\n",
        "            result = self.chain.invoke(prompt_vars)\n",
        "\n",
        "            import re, json\n",
        "\n",
        "            # Extract the actual JSON string from the 'text' key\n",
        "            if isinstance(result, dict) and \"text\" in result:\n",
        "                result_text = result[\"text\"]\n",
        "            else:\n",
        "                result_text = result\n",
        "\n",
        "            # Parse result_text\n",
        "            if isinstance(result_text, str):\n",
        "                try:\n",
        "                    parsed_result = json.loads(result_text.strip())\n",
        "                except json.JSONDecodeError:\n",
        "                    json_str = re.search(r\"\\{[\\s\\S]*\\}\", result_text).group(0)\n",
        "                    parsed_result = json.loads(json_str)\n",
        "            elif isinstance(result_text, dict):\n",
        "                parsed_result = result_text\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected result type.\")\n",
        "\n",
        "            # ‚úÖ Now this should work:\n",
        "            spotify_rec = parsed_result.get(\"recommendations\", {}).get(\"content\", {}).get(\"spotify\")\n",
        "            if spotify_rec:\n",
        "                spotify_playlist = self.get_spotify_recommendation(spotify_rec)\n",
        "                # print(\"üéµ Spotify playlist result:\\n\", json.dumps(spotify_playlist, indent=2))\n",
        "                parsed_result[\"recommendations\"][\"content\"][\"spotify\"][\"playlist\"] = spotify_playlist\n",
        "\n",
        "            return parsed_result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"‚ùå Run error:\", e)\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP0Zfbm6I889",
        "outputId": "f7bf556c-a070-435f-ec32-b3ef43aca1f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-9-3375132153.py:131: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  self.chain = LLMChain(prompt=self.prompt, llm=self.llm, verbose=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"sleepAssessment\": {\n",
            "    \"issue\": \"Difficulty falling asleep\",\n",
            "    \"confidence\": 0.85,\n",
            "    \"severity\": \"medium\",\n",
            "    \"summary\": \"User reports taking over an hour to fall asleep, likely influenced by late afternoon coffee consumption.\",\n",
            "    \"sleepHistoryDetected\": false,\n",
            "    \"userMood\": \"tired\",\n",
            "    \"sleepDurationTrend\": \"unknown\"\n",
            "  },\n",
            "  \"routineRecommendation\": {\n",
            "    \"windDown\": [\n",
            "      \"Reading a calming book\",\n",
            "      \"Practicing deep breathing exercises\",\n",
            "      \"Listening to soft music or guided meditation\"\n",
            "    ],\n",
            "    \"avoidBeforeBed\": [\n",
            "      \"Caffeine\",\n",
            "      \"Screens (phones, computers)\"\n",
            "    ],\n",
            "    \"optimalSleepTime\": \"10:30 PM\",\n",
            "    \"optimalWakeTime\": \"6:30 AM\",\n",
            "    \"reminders\": [\n",
            "      \"Set a caffeine cut-off time of 2 PM\",\n",
            "      \"Establish a consistent bedtime routine\"\n",
            "    ]\n",
            "  },\n",
            "  \"tips\": {\n",
            "    \"immediateActions\": [\n",
            "      \"Limit coffee intake to the morning hours\",\n",
            "      \"Dim lights in the evening to signal winding down\"\n",
            "    ],\n",
            "    \"lifestyleChanges\": [\n",
            "      \"Implement a regular sleep schedule\",\n",
            "      \"Incorporate relaxation techniques before bed\"\n",
            "    ],\n",
            "    \"environmentSuggestions\": [\n",
            "      \"Ensure a dark, cool, and quiet sleep environment\",\n",
            "      \"Consider using blackout curtains\"\n",
            "    ]\n",
            "  },\n",
            "  \"recommendations\": {\n",
            "    \"immediate\": [\n",
            "      \"Stop drinking coffee after 2 PM\",\n",
            "      \"Engage in a calming wind-down routine\",\n",
            "      \"Avoid screens at least an hour before bed\"\n",
            "    ],\n",
            "    \"content\": {\n",
            "      \"spotify\": {\n",
            "        \"genres\": [\n",
            "          \"ambient\",\n",
            "          \"classical\"\n",
            "        ],\n",
            "        \"energy\": 0.2,\n",
            "        \"valence\": 0.7,\n",
            "        \"mood\": \"relaxing\",\n",
            "        \"playlist\": {\n",
            "          \"query\": \"ambient classical relaxing\",\n",
            "          \"total\": 5,\n",
            "          \"playlists\": [\n",
            "            {\n",
            "              \"name\": \"New Age Nature Music\",\n",
            "              \"spotify_url\": \"https://open.spotify.com/playlist/2yjNRiJrOfSUpJ1TmUN5Uf\",\n",
            "              \"duration_seconds\": 28800,\n",
            "              \"thumbnail\": \"https://image-cdn-ak.spotifycdn.com/image/ab67706c0000da8461a9f5ec01d72b76ae58366c\",\n",
            "              \"artist_details\": {\n",
            "                \"name\": \"Little Symphony Collective\",\n",
            "                \"url\": \"https://open.spotify.com/user/31753dd2wjc3to4mazvp2p7jojv4\"\n",
            "              }\n",
            "            },\n",
            "            {\n",
            "              \"name\": \"Massage Mood\",\n",
            "              \"spotify_url\": \"https://open.spotify.com/playlist/0tDGURILIw9JppZZz59KXF\",\n",
            "              \"duration_seconds\": 25320,\n",
            "              \"thumbnail\": \"https://image-cdn-ak.spotifycdn.com/image/ab67706c0000d72c7edb1bbd50cd4998b2638561\",\n",
            "              \"artist_details\": {\n",
            "                \"name\": \"Isaac Shepard\",\n",
            "                \"url\": \"https://open.spotify.com/user/isaacshepard\"\n",
            "              }\n",
            "            },\n",
            "            {\n",
            "              \"name\": \"Beautiful calm classical music\",\n",
            "              \"spotify_url\": \"https://open.spotify.com/playlist/0Qxcw5GLq2XOAqZuMJnHPd\",\n",
            "              \"duration_seconds\": 5200,\n",
            "              \"thumbnail\": \"https://image-cdn-ak.spotifycdn.com/image/ab67706c0000d72c05e9435431abc44db332ba4f\",\n",
            "              \"artist_details\": {\n",
            "                \"name\": \"Paula Wijker\",\n",
            "                \"url\": \"https://open.spotify.com/user/paula-wijker\"\n",
            "              }\n",
            "            },\n",
            "            {\n",
            "              \"name\": \"60 BPM Sleep Music\",\n",
            "              \"spotify_url\": \"https://open.spotify.com/playlist/05wvLbmiAwCUjT10IkOpJ7\",\n",
            "              \"duration_seconds\": 22320,\n",
            "              \"thumbnail\": \"https://image-cdn-fa.spotifycdn.com/image/ab67706c0000da843fc957e1f3e2613e630f49c1\",\n",
            "              \"artist_details\": {\n",
            "                \"name\": \"Nature Wellness Music\",\n",
            "                \"url\": \"https://open.spotify.com/user/314hek7iqqo447jzgrumwbhmpsmi\"\n",
            "              }\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"disorderCheck\": {\n",
            "    \"riskLevel\": \"medium\",\n",
            "    \"symptoms\": [\n",
            "      \"Difficulty falling asleep\",\n",
            "      \"Prolonged wakefulness in bed\"\n",
            "    ],\n",
            "    \"recommendations\": [\n",
            "      \"Consider consulting a sleep specialist if issues persist\",\n",
            "      \"Maintain a sleep diary to track patterns\"\n",
            "    ],\n",
            "    \"complianceRisk\": \"medium\"\n",
            "  },\n",
            "  \"followUp\": {\n",
            "    \"checkInPeriod\": \"weekly\",\n",
            "    \"trackMetrics\": [\n",
            "      \"hours slept\",\n",
            "      \"time taken to fall asleep\",\n",
            "      \"caffeine intake\"\n",
            "    ],\n",
            "    \"goals\": [\n",
            "      \"Reduce latency to < 20 minutes\",\n",
            "      \"Achieve at least 7 hours of sleep\"\n",
            "    ]\n",
            "  },\n",
            "  \"metadata\": {\n",
            "    \"wordCount\": 242,\n",
            "    \"timeOfDayMentioned\": \"afternoon\",\n",
            "    \"contextTags\": [\n",
            "      \"caffeine\",\n",
            "      \"sleep difficulties\"\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "agent = SleepCoachAgent(api_key=key)\n",
        "response = agent.run(\"I have trouble falling asleep and usually spend over an hour awake in bed. I also drink coffee late in the afternoon.\")\n",
        "print(json.dumps(response, indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
